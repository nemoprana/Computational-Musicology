---
title: "Exploring SAAN"
subtitle: "Comparing the self-image to the raw data"
author: "Nemo Woudenberg"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(plotly)
library(compmus)
```

An introduction to the data
====================================
## Empty {data-width="100"}

## Column {data-width="800"}

### Introduction

#### ALL NEW INFORMATION IS ON [The chordogram!] PAGE!!

Here I will be comparing some interesting data. On the one hand we have one side of the data:

 - My dad has 19 total songs on spotify: 11 songs played with the band 'Mad Stream' and 8 more songs with the band 'Sleepers Awake At Night'. These two bands consist of mostly the same musicians and have (in my opinion) a very similar sound. 

I want to use the songs of these two bands to have some fun and make an interesting comparison with another part of the data:

 - The band 'Sleepers Awake At Night' (from now on I will refer to them as SAAN, also when SAANs music is mentioned I actually mean the music of SAAN + Mad Stream ) has a public playlist on their spotify profile called 'radio SAAN'. The playlist consists of 94 songs and features some SAAN and Mad Stream songs, but most of the music is from different bands. 

The purpose of this playlist is to give the listener some music that is kind of like the music of SAAN, or maybe has been an inspiration for the band members. My research will therefore try to look at the next question:

Does SAAN sound like they think they do?

By comparing the playlist with their own songs we might get some insight into the kinds of things the members of SAAN listen to in the music they appreciate. For example: we might find that most of the songs in the radio SAAN playlist have a high score on valence. If the songs made by SAAN also tend to have a high valence, we could conclude that they appreciate a good mood! In [The first data] we will look at some introductory visualizations exploring some characteristics of SAANs music.

## Empty {data-width="100"}

The first data {data-navmenu="First Datas"}
====================================

## Graph {data-width="700"}

### First chart

```{r}
SAAN <- get_playlist_audio_features("", "2eBYBIoOoB3AIKyGvbVo3R")

gg_temp_val <- ggplot(SAAN, aes(tempo, valence, color = track.album.name)) +
  geom_point() +
  theme_minimal() +
  labs(x = "Tempo", y = "Valence", color = "Album") 

ggplotly(gg_temp_val)
```

## Text {data-width="300"}

### A small conclusion

The graph here on the left show us a quick overview of the valence and tempo of all the SAAN songs. We notice something interesting for the valence values: most of the songs score above 0.5, but 4 of them eek out below from under 0.3! And the low-valence songs are from different albums, so its not like they had an emo phase... We will have to look further into this!

The tempo values are pretty much smeared out, even though 125 bpm is preferably avoided. 

Spectogram {data-navmenu="First Datas" data-orientation=rows}
====================================
## Text {data-height="300"}

### Time for a spectogram!

Below here are two visualizations for the song 'Just You and Me'. In [The first data] this was the song with the lowest valence and an high tempo compared to the other low-valence songs (on the bottom-right).

Interesting to note in the timbre is that c05 actually roughly indicates where the voice enters! Bright yellow means there is voice present and the darker regions show absence of voice. The pitch on the other hand show us a very different distribution of colors. This gives us a good clue as to where the different sections in the song are. The part from ~60s until ~100s show us an interesting thing: the yellow parts on C# and F# are actually quite clearly what the guitar is playing. Because there is not too much harmonic information the lines are very distinct!

## Graph {data-height="700"}

### Timbre

```{r}
yandm <-
  get_tidy_audio_analysis("1e7FgxUJ8WAdbVMrpaFpsE") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "max", norm = "chebyshev"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "max", norm = "chebyshev"              # Change summary & norm.
      )
  )

yandm|>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

### Pitch

```{r}
you_and_me <-
  get_tidy_audio_analysis("1e7FgxUJ8WAdbVMrpaFpsE") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

you_and_me |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

The chordogram! {data-navmenu="First Datas"}
====================================

## Graph {data-width="500"}

### Chordogram

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

tpf <-
  get_tidy_audio_analysis("1yVIMaoLkTQkqhghCiTrNy") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"
      )
  )

tpf |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

## Text {data-width="500"}

### What to see

Here on the left is a chordogram for the song called 20point50! This one is very interesting and I will tell you why. This song (and most music in the corpus) is quite vampy (which means that the song just hangs around one chord / harmony instead of going all different hamonic places). This means that the keygram I made for this song actually shows very little matter of interest (check it out on the [Keygram] page!). When I tried making a chordogram, initially it didn't really work out until I sorted on sections. Now here you can really see what is going on! 

Most of the song is based around a C7 vamp (actually more based on a riff but that is not really important), however there are the little sections in between where the band basically just straight up sings a big fat F7 chord. The chordogram really shows this and it turned out great!

Keygram {data-navmenu="First Datas"}
====================================

## Graph {data-width="700"}

### Chordogram

```{r}
tpf |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```